[{"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\chat.ts":"1","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\google.ts":"2","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\home.context.tsx":"3","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\home.state.tsx":"4","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\home.tsx":"5","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\index.ts":"6","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\models.ts":"7","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\index.tsx":"8","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\_app.tsx":"9","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\_document.tsx":"10","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Buttons\\SidebarActionButton\\index.ts":"11","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Buttons\\SidebarActionButton\\SidebarActionButton.tsx":"12","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\Chat.tsx":"13","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ChatInput.tsx":"14","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ChatLoader.tsx":"15","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ChatMessage.tsx":"16","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ErrorMessageDiv.tsx":"17","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\MemoizedChatMessage.tsx":"18","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ModelSelect.tsx":"19","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\PluginSelect.tsx":"20","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\PromptList.tsx":"21","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\Regenerate.tsx":"22","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\SystemPrompt.tsx":"23","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\Temperature.tsx":"24","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\VariableModal.tsx":"25","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\Chatbar.context.tsx":"26","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\Chatbar.state.tsx":"27","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\Chatbar.tsx":"28","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\ChatbarSettings.tsx":"29","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\ChatFolders.tsx":"30","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\ClearConversations.tsx":"31","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\Conversation.tsx":"32","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\Conversations.tsx":"33","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\PluginKeys.tsx":"34","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Folder\\Folder.tsx":"35","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Folder\\index.ts":"36","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Markdown\\CodeBlock.tsx":"37","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Markdown\\MemoizedReactMarkdown.tsx":"38","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Mobile\\Navbar.tsx":"39","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\Prompt.tsx":"40","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\PromptbarSettings.tsx":"41","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\PromptFolders.tsx":"42","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\PromptModal.tsx":"43","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\Prompts.tsx":"44","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\index.ts":"45","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\PromptBar.context.tsx":"46","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\Promptbar.state.tsx":"47","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\Promptbar.tsx":"48","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Search\\index.ts":"49","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Search\\Search.tsx":"50","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Settings\\Import.tsx":"51","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Settings\\Key.tsx":"52","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Settings\\SettingDialog.tsx":"53","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\components\\OpenCloseButton.tsx":"54","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\index.ts":"55","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\Sidebar.tsx":"56","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\SidebarButton.tsx":"57","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Spinner\\index.ts":"58","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Spinner\\Spinner.tsx":"59"},{"size":1972,"mtime":1702412232734,"results":"60","hashOfConfig":"61"},{"size":4709,"mtime":1702412232743,"results":"62","hashOfConfig":"61"},{"size":884,"mtime":1702412232758,"results":"63","hashOfConfig":"61"},{"size":1557,"mtime":1705497184633,"results":"64","hashOfConfig":"61"},{"size":12410,"mtime":1705497180720,"results":"65","hashOfConfig":"61"},{"size":54,"mtime":1702412232787,"results":"66","hashOfConfig":"61"},{"size":2547,"mtime":1705499651157,"results":"67","hashOfConfig":"61"},{"size":58,"mtime":1702412232799,"results":"68","hashOfConfig":"61"},{"size":660,"mtime":1702412232717,"results":"69","hashOfConfig":"61"},{"size":638,"mtime":1702412232723,"results":"70","hashOfConfig":"61"},{"size":49,"mtime":1702412232185,"results":"71","hashOfConfig":"61"},{"size":406,"mtime":1702412232173,"results":"72","hashOfConfig":"61"},{"size":17582,"mtime":1702412232199,"results":"73","hashOfConfig":"61"},{"size":13144,"mtime":1702412232209,"results":"74","hashOfConfig":"61"},{"size":669,"mtime":1702412232216,"results":"75","hashOfConfig":"61"},{"size":10468,"mtime":1702412232224,"results":"76","hashOfConfig":"61"},{"size":789,"mtime":1702412232231,"results":"77","hashOfConfig":"61"},{"size":261,"mtime":1702412232239,"results":"78","hashOfConfig":"61"},{"size":2082,"mtime":1702412232246,"results":"79","hashOfConfig":"61"},{"size":2848,"mtime":1702412232253,"results":"80","hashOfConfig":"61"},{"size":1243,"mtime":1702412232260,"results":"81","hashOfConfig":"61"},{"size":922,"mtime":1702412232268,"results":"82","hashOfConfig":"61"},{"size":6660,"mtime":1702412232275,"results":"83","hashOfConfig":"61"},{"size":2112,"mtime":1702412232283,"results":"84","hashOfConfig":"61"},{"size":3809,"mtime":1702412232290,"results":"85","hashOfConfig":"61"},{"size":971,"mtime":1705492388490,"results":"86","hashOfConfig":"61"},{"size":252,"mtime":1702412232314,"results":"87","hashOfConfig":"61"},{"size":7877,"mtime":1705492388492,"results":"88","hashOfConfig":"61"},{"size":2310,"mtime":1705492388494,"results":"89","hashOfConfig":"61"},{"size":1703,"mtime":1702412232338,"results":"90","hashOfConfig":"61"},{"size":1575,"mtime":1702412232358,"results":"91","hashOfConfig":"61"},{"size":5212,"mtime":1702412232367,"results":"92","hashOfConfig":"61"},{"size":540,"mtime":1702412232375,"results":"93","hashOfConfig":"61"},{"size":9154,"mtime":1702412232384,"results":"94","hashOfConfig":"61"},{"size":5173,"mtime":1702412232395,"results":"95","hashOfConfig":"61"},{"size":36,"mtime":1702412232405,"results":"96","hashOfConfig":"61"},{"size":2702,"mtime":1702412232417,"results":"97","hashOfConfig":"61"},{"size":258,"mtime":1702412232426,"results":"98","hashOfConfig":"61"},{"size":703,"mtime":1702412232439,"results":"99","hashOfConfig":"61"},{"size":3492,"mtime":1702412232482,"results":"100","hashOfConfig":"61"},{"size":126,"mtime":1702412232513,"results":"101","hashOfConfig":"61"},{"size":1679,"mtime":1702412232494,"results":"102","hashOfConfig":"61"},{"size":4964,"mtime":1702412232503,"results":"103","hashOfConfig":"61"},{"size":445,"mtime":1702412232523,"results":"104","hashOfConfig":"61"},{"size":39,"mtime":1702412232530,"results":"105","hashOfConfig":"61"},{"size":580,"mtime":1702412232450,"results":"106","hashOfConfig":"61"},{"size":234,"mtime":1702412232460,"results":"107","hashOfConfig":"61"},{"size":4176,"mtime":1702412232467,"results":"108","hashOfConfig":"61"},{"size":36,"mtime":1702412232553,"results":"109","hashOfConfig":"61"},{"size":1100,"mtime":1702412232542,"results":"110","hashOfConfig":"61"},{"size":1265,"mtime":1702412232565,"results":"111","hashOfConfig":"61"},{"size":2321,"mtime":1702412232574,"results":"112","hashOfConfig":"61"},{"size":3562,"mtime":1702412232582,"results":"113","hashOfConfig":"61"},{"size":1323,"mtime":1702412232622,"results":"114","hashOfConfig":"61"},{"size":37,"mtime":1702412232630,"results":"115","hashOfConfig":"61"},{"size":3444,"mtime":1702412232597,"results":"116","hashOfConfig":"61"},{"size":488,"mtime":1702412232607,"results":"117","hashOfConfig":"61"},{"size":37,"mtime":1702412232650,"results":"118","hashOfConfig":"61"},{"size":951,"mtime":1702412232641,"results":"119","hashOfConfig":"61"},{"filePath":"120","messages":"121","suppressedMessages":"122","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"1rbqh96",{"filePath":"123","messages":"124","suppressedMessages":"125","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"126","messages":"127","suppressedMessages":"128","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"129","messages":"130","suppressedMessages":"131","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"132","messages":"133","suppressedMessages":"134","errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"135"},{"filePath":"136","messages":"137","suppressedMessages":"138","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"139","messages":"140","suppressedMessages":"141","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"142","messages":"143","suppressedMessages":"144","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"145","messages":"146","suppressedMessages":"147","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"148","messages":"149","suppressedMessages":"150","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"151","messages":"152","suppressedMessages":"153","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"154","messages":"155","suppressedMessages":"156","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"157","messages":"158","suppressedMessages":"159","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"160"},{"filePath":"161","messages":"162","suppressedMessages":"163","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"164"},{"filePath":"165","messages":"166","suppressedMessages":"167","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"168","messages":"169","suppressedMessages":"170","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"171","messages":"172","suppressedMessages":"173","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"174","messages":"175","suppressedMessages":"176","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"177","messages":"178","suppressedMessages":"179","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"180","messages":"181","suppressedMessages":"182","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"183","messages":"184","suppressedMessages":"185","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"186","messages":"187","suppressedMessages":"188","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"189","messages":"190","suppressedMessages":"191","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"192","messages":"193","suppressedMessages":"194","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"195","messages":"196","suppressedMessages":"197","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"198","messages":"199","suppressedMessages":"200","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"201","messages":"202","suppressedMessages":"203","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"204","messages":"205","suppressedMessages":"206","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"207"},{"filePath":"208","messages":"209","suppressedMessages":"210","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"211","messages":"212","suppressedMessages":"213","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"214","messages":"215","suppressedMessages":"216","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"217","messages":"218","suppressedMessages":"219","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"220","messages":"221","suppressedMessages":"222","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"223","messages":"224","suppressedMessages":"225","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"226","messages":"227","suppressedMessages":"228","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"229","messages":"230","suppressedMessages":"231","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"232","messages":"233","suppressedMessages":"234","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"235","messages":"236","suppressedMessages":"237","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"238","messages":"239","suppressedMessages":"240","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"241","messages":"242","suppressedMessages":"243","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"244","messages":"245","suppressedMessages":"246","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"247","messages":"248","suppressedMessages":"249","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"250","messages":"251","suppressedMessages":"252","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"253","messages":"254","suppressedMessages":"255","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"256","messages":"257","suppressedMessages":"258","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"259","messages":"260","suppressedMessages":"261","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"262","messages":"263","suppressedMessages":"264","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"265","messages":"266","suppressedMessages":"267","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"268"},{"filePath":"269","messages":"270","suppressedMessages":"271","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"272","messages":"273","suppressedMessages":"274","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"275","messages":"276","suppressedMessages":"277","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"278","messages":"279","suppressedMessages":"280","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"281","messages":"282","suppressedMessages":"283","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"284","messages":"285","suppressedMessages":"286","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"287","messages":"288","suppressedMessages":"289","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"290","messages":"291","suppressedMessages":"292","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"293","messages":"294","suppressedMessages":"295","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"296","messages":"297","suppressedMessages":"298","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"299","messages":"300","suppressedMessages":"301","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\chat.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\google.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\home.context.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\home.state.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\home.tsx",["302","303","304"],[],"import { useEffect, useRef, useState } from 'react';\r\nimport { useQuery } from 'react-query';\r\n\r\nimport { GetServerSideProps } from 'next';\r\nimport { useTranslation } from 'next-i18next';\r\nimport { serverSideTranslations } from 'next-i18next/serverSideTranslations';\r\nimport Head from 'next/head';\r\n\r\nimport { useCreateReducer } from '@/hooks/useCreateReducer';\r\n\r\nimport useErrorService from '@/services/errorService';\r\nimport useApiService from '@/services/useApiService';\r\n\r\nimport {\r\n  cleanConversationHistory,\r\n  cleanSelectedConversation,\r\n} from '@/utils/app/clean';\r\nimport { DEFAULT_SYSTEM_PROMPT, DEFAULT_TEMPERATURE } from '@/utils/app/const';\r\nimport {\r\n  saveConversation,\r\n  saveConversations,\r\n  updateConversation,\r\n} from '@/utils/app/conversation';\r\nimport { saveFolders } from '@/utils/app/folders';\r\nimport { savePrompts } from '@/utils/app/prompts';\r\nimport { getSettings } from '@/utils/app/settings';\r\n\r\nimport { Conversation } from '@/types/chat';\r\nimport { KeyValuePair } from '@/types/data';\r\nimport { FolderInterface, FolderType } from '@/types/folder';\r\nimport { OpenAIModelID, OpenAIModels, fallbackModelID } from '@/types/openai';\r\nimport { Prompt } from '@/types/prompt';\r\n\r\nimport { Chat } from '@/components/Chat/Chat';\r\nimport { Chatbar } from '@/components/Chatbar/Chatbar';\r\nimport { Navbar } from '@/components/Mobile/Navbar';\r\nimport Promptbar from '@/components/Promptbar';\r\n\r\nimport HomeContext from './home.context';\r\nimport { HomeInitialState, initialState } from './home.state';\r\n\r\nimport { v4 as uuidv4 } from 'uuid';\r\n\r\ninterface Props {\r\n  serverSideApiKeyIsSet: boolean;\r\n  serverSidePluginKeysSet: boolean;\r\n  defaultModelId: OpenAIModelID;\r\n}\r\n\r\nconst Home = ({\r\n  serverSideApiKeyIsSet,\r\n  serverSidePluginKeysSet,\r\n  defaultModelId,\r\n}: Props) => {\r\n  const { t } = useTranslation('chat');\r\n  const { getModels } = useApiService();\r\n  const { getModelsError } = useErrorService();\r\n  const [initialRender, setInitialRender] = useState<boolean>(true);\r\n\r\n  const contextValue = useCreateReducer<HomeInitialState>({\r\n    initialState,\r\n  });\r\n\r\n  const {\r\n    state: {\r\n      apiKey,\r\n      lightMode,\r\n      folders,\r\n      conversations,\r\n      selectedConversation,\r\n      prompts,\r\n      temperature,\r\n    },\r\n    dispatch,\r\n  } = contextValue;\r\n\r\n  const stopConversationRef = useRef<boolean>(false);\r\n\r\n  const { data, error, refetch } = useQuery(\r\n    ['GetModels', apiKey, serverSideApiKeyIsSet],\r\n    ({ signal }) => {\r\n      if (!apiKey && !serverSideApiKeyIsSet) return null;\r\n\r\n      return getModels(\r\n        {\r\n          key: apiKey,\r\n        },\r\n        signal,\r\n      );\r\n    },\r\n    { enabled: true, refetchOnMount: false },\r\n  );\r\n\r\n  useEffect(() => {\r\n    if (data) dispatch({ field: 'models', value: data });\r\n  }, [data, dispatch]);\r\n\r\n  useEffect(() => {\r\n    dispatch({ field: 'modelError', value: getModelsError(error) });\r\n  }, [dispatch, error, getModelsError]);\r\n\r\n  // FETCH MODELS ----------------------------------------------\r\n\r\n  const handleSelectConversation = (conversation: Conversation) => {\r\n    dispatch({\r\n      field: 'selectedConversation',\r\n      value: conversation,\r\n    });\r\n\r\n    saveConversation(conversation);\r\n  };\r\n\r\n  // FOLDER OPERATIONS  --------------------------------------------\r\n\r\n  const handleCreateFolder = (name: string, type: FolderType) => {\r\n    const newFolder: FolderInterface = {\r\n      id: uuidv4(),\r\n      name,\r\n      type,\r\n    };\r\n\r\n    const updatedFolders = [...folders, newFolder];\r\n\r\n    dispatch({ field: 'folders', value: updatedFolders });\r\n    saveFolders(updatedFolders);\r\n  };\r\n\r\n  const handleDeleteFolder = (folderId: string) => {\r\n    const updatedFolders = folders.filter((f) => f.id !== folderId);\r\n    dispatch({ field: 'folders', value: updatedFolders });\r\n    saveFolders(updatedFolders);\r\n\r\n    const updatedConversations: Conversation[] = conversations.map((c) => {\r\n      if (c.folderId === folderId) {\r\n        return {\r\n          ...c,\r\n          folderId: null,\r\n        };\r\n      }\r\n\r\n      return c;\r\n    });\r\n\r\n    dispatch({ field: 'conversations', value: updatedConversations });\r\n    saveConversations(updatedConversations);\r\n\r\n    const updatedPrompts: Prompt[] = prompts.map((p) => {\r\n      if (p.folderId === folderId) {\r\n        return {\r\n          ...p,\r\n          folderId: null,\r\n        };\r\n      }\r\n\r\n      return p;\r\n    });\r\n\r\n    dispatch({ field: 'prompts', value: updatedPrompts });\r\n    savePrompts(updatedPrompts);\r\n  };\r\n\r\n  const handleUpdateFolder = (folderId: string, name: string) => {\r\n    const updatedFolders = folders.map((f) => {\r\n      if (f.id === folderId) {\r\n        return {\r\n          ...f,\r\n          name,\r\n        };\r\n      }\r\n\r\n      return f;\r\n    });\r\n\r\n    dispatch({ field: 'folders', value: updatedFolders });\r\n\r\n    saveFolders(updatedFolders);\r\n  };\r\n\r\n  // CONVERSATION OPERATIONS  --------------------------------------------\r\n\r\n  const handleNewConversation = () => {\r\n    const lastConversation = conversations[conversations.length - 1];\r\n\r\n    const newConversation: Conversation = {\r\n      id: uuidv4(),\r\n      name: t('New Conversation'),\r\n      messages: [],\r\n      model: lastConversation?.model || {\r\n        id: OpenAIModels[defaultModelId].id,\r\n        name: OpenAIModels[defaultModelId].name,\r\n        maxLength: OpenAIModels[defaultModelId].maxLength,\r\n        tokenLimit: OpenAIModels[defaultModelId].tokenLimit,\r\n      },\r\n      prompt: DEFAULT_SYSTEM_PROMPT,\r\n      temperature: lastConversation?.temperature ?? DEFAULT_TEMPERATURE,\r\n      folderId: null,\r\n    };\r\n\r\n    const updatedConversations = [...conversations, newConversation];\r\n\r\n    dispatch({ field: 'selectedConversation', value: newConversation });\r\n    dispatch({ field: 'conversations', value: updatedConversations });\r\n\r\n    saveConversation(newConversation);\r\n    saveConversations(updatedConversations);\r\n\r\n    dispatch({ field: 'loading', value: false });\r\n  };\r\n\r\n  const handleUpdateConversation = (\r\n    conversation: Conversation,\r\n    data: KeyValuePair,\r\n  ) => {\r\n    const updatedConversation = {\r\n      ...conversation,\r\n      [data.key]: data.value,\r\n    };\r\n\r\n    const { single, all } = updateConversation(\r\n      updatedConversation,\r\n      conversations,\r\n    );\r\n\r\n    dispatch({ field: 'selectedConversation', value: single });\r\n    dispatch({ field: 'conversations', value: all });\r\n  };\r\n\r\n  // EFFECTS  --------------------------------------------\r\n\r\n  useEffect(() => {\r\n    if (window.innerWidth < 640) {\r\n      dispatch({ field: 'showChatbar', value: false });\r\n    }\r\n  }, [selectedConversation]);\r\n\r\n  useEffect(() => {\r\n    defaultModelId &&\r\n      dispatch({ field: 'defaultModelId', value: defaultModelId });\r\n    serverSideApiKeyIsSet &&\r\n      dispatch({\r\n        field: 'serverSideApiKeyIsSet',\r\n        value: serverSideApiKeyIsSet,\r\n      });\r\n    serverSidePluginKeysSet &&\r\n      dispatch({\r\n        field: 'serverSidePluginKeysSet',\r\n        value: serverSidePluginKeysSet,\r\n      });\r\n  }, [defaultModelId, serverSideApiKeyIsSet, serverSidePluginKeysSet]);\r\n\r\n  // ON LOAD --------------------------------------------\r\n\r\n  useEffect(() => {\r\n    const settings = getSettings();\r\n    if (settings.theme) {\r\n      dispatch({\r\n        field: 'lightMode',\r\n        value: settings.theme,\r\n      });\r\n    }\r\n\r\n    const apiKey = localStorage.getItem('apiKey');\r\n\r\n    if (serverSideApiKeyIsSet) {\r\n      dispatch({ field: 'apiKey', value: '' });\r\n\r\n      localStorage.removeItem('apiKey');\r\n    } else if (apiKey) {\r\n      dispatch({ field: 'apiKey', value: apiKey });\r\n    }\r\n\r\n    const pluginKeys = localStorage.getItem('pluginKeys');\r\n    if (serverSidePluginKeysSet) {\r\n      dispatch({ field: 'pluginKeys', value: [] });\r\n      localStorage.removeItem('pluginKeys');\r\n    } else if (pluginKeys) {\r\n      dispatch({ field: 'pluginKeys', value: pluginKeys });\r\n    }\r\n\r\n    if (window.innerWidth < 640) {\r\n      dispatch({ field: 'showChatbar', value: false });\r\n      dispatch({ field: 'showPromptbar', value: false });\r\n    }\r\n\r\n    const showChatbar = localStorage.getItem('showChatbar');\r\n    if (showChatbar) {\r\n      dispatch({ field: 'showChatbar', value: showChatbar === 'true' });\r\n    }\r\n\r\n    const showPromptbar = localStorage.getItem('showPromptbar');\r\n    if (showPromptbar) {\r\n      dispatch({ field: 'showPromptbar', value: showPromptbar === 'true' });\r\n    }\r\n\r\n    const folders = localStorage.getItem('folders');\r\n    if (folders) {\r\n      dispatch({ field: 'folders', value: JSON.parse(folders) });\r\n    }\r\n\r\n    const prompts = localStorage.getItem('prompts');\r\n    if (prompts) {\r\n      dispatch({ field: 'prompts', value: JSON.parse(prompts) });\r\n    }\r\n\r\n    const conversationHistory = localStorage.getItem('conversationHistory');\r\n    if (conversationHistory) {\r\n      const parsedConversationHistory: Conversation[] =\r\n        JSON.parse(conversationHistory);\r\n      const cleanedConversationHistory = cleanConversationHistory(\r\n        parsedConversationHistory,\r\n      );\r\n\r\n      dispatch({ field: 'conversations', value: cleanedConversationHistory });\r\n    }\r\n\r\n    const selectedConversation = localStorage.getItem('selectedConversation');\r\n    if (selectedConversation) {\r\n      const parsedSelectedConversation: Conversation =\r\n        JSON.parse(selectedConversation);\r\n      const cleanedSelectedConversation = cleanSelectedConversation(\r\n        parsedSelectedConversation,\r\n      );\r\n\r\n      dispatch({\r\n        field: 'selectedConversation',\r\n        value: cleanedSelectedConversation,\r\n      });\r\n    } else {\r\n      const lastConversation = conversations[conversations.length - 1];\r\n      dispatch({\r\n        field: 'selectedConversation',\r\n        value: {\r\n          id: uuidv4(),\r\n          name: t('New Conversation'),\r\n          messages: [],\r\n          model: OpenAIModels[defaultModelId],\r\n          prompt: DEFAULT_SYSTEM_PROMPT,\r\n          temperature: lastConversation?.temperature ?? DEFAULT_TEMPERATURE,\r\n          folderId: null,\r\n        },\r\n      });\r\n    }\r\n  }, [\r\n    defaultModelId,\r\n    dispatch,\r\n    serverSideApiKeyIsSet,\r\n    serverSidePluginKeysSet,\r\n  ]);\r\n\r\n  return (\r\n    <HomeContext.Provider\r\n      value={{\r\n        ...contextValue,\r\n        handleNewConversation,\r\n        handleCreateFolder,\r\n        handleDeleteFolder,\r\n        handleUpdateFolder,\r\n        handleSelectConversation,\r\n        handleUpdateConversation,\r\n      }}\r\n    >\r\n      <Head>\r\n        <title>Chatbot UI</title>\r\n        <meta name=\"description\" content=\"ChatGPT but better.\" />\r\n        <meta\r\n          name=\"viewport\"\r\n          content=\"height=device-height ,width=device-width, initial-scale=1, user-scalable=no\"\r\n        />\r\n        <link rel=\"icon\" href=\"/favicon.ico\" />\r\n      </Head>\r\n      {selectedConversation && (\r\n        <main\r\n          className={`flex h-screen w-screen flex-col text-sm text-white dark:text-white ${lightMode}`}\r\n        >\r\n          <div className=\"fixed top-0 w-full sm:hidden\">\r\n            <Navbar\r\n              selectedConversation={selectedConversation}\r\n              onNewConversation={handleNewConversation}\r\n            />\r\n          </div>\r\n\r\n          <div className=\"flex h-full w-full pt-[48px] sm:pt-0\">\r\n            <Chatbar />\r\n\r\n            <div className=\"flex flex-1\">\r\n              <Chat stopConversationRef={stopConversationRef} />\r\n            </div>\r\n\r\n            <Promptbar />\r\n          </div>\r\n        </main>\r\n      )}\r\n    </HomeContext.Provider>\r\n  );\r\n};\r\nexport default Home;\r\n\r\nexport const getServerSideProps: GetServerSideProps = async ({ locale }) => {\r\n  const defaultModelId =\r\n    (process.env.DEFAULT_MODEL &&\r\n      Object.values(OpenAIModelID).includes(\r\n        process.env.DEFAULT_MODEL as OpenAIModelID,\r\n      ) &&\r\n      process.env.DEFAULT_MODEL) ||\r\n    fallbackModelID;\r\n\r\n  let serverSidePluginKeysSet = false;\r\n\r\n  const googleApiKey = process.env.GOOGLE_API_KEY;\r\n  const googleCSEId = process.env.GOOGLE_CSE_ID;\r\n\r\n  if (googleApiKey && googleCSEId) {\r\n    serverSidePluginKeysSet = true;\r\n  }\r\n\r\n  return {\r\n    props: {\r\n      serverSideApiKeyIsSet: !!process.env.OPENAI_API_KEY,\r\n      defaultModelId,\r\n      serverSidePluginKeysSet,\r\n      ...(await serverSideTranslations(locale ?? 'en', [\r\n        'common',\r\n        'chat',\r\n        'sidebar',\r\n        'markdown',\r\n        'promptbar',\r\n        'settings',\r\n      ])),\r\n    },\r\n  };\r\n};\r\n","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\home\\index.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\api\\models.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\index.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\_app.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\pages\\_document.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Buttons\\SidebarActionButton\\index.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Buttons\\SidebarActionButton\\SidebarActionButton.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\Chat.tsx",["305"],[],"import { IconClearAll, IconSettings } from '@tabler/icons-react';\nimport {\n  MutableRefObject,\n  memo,\n  useCallback,\n  useContext,\n  useEffect,\n  useRef,\n  useState,\n} from 'react';\nimport toast from 'react-hot-toast';\n\nimport { useTranslation } from 'next-i18next';\n\nimport { getEndpoint } from '@/utils/app/api';\nimport {\n  saveConversation,\n  saveConversations,\n  updateConversation,\n} from '@/utils/app/conversation';\nimport { throttle } from '@/utils/data/throttle';\n\nimport { ChatBody, Conversation, Message } from '@/types/chat';\nimport { Plugin } from '@/types/plugin';\n\nimport HomeContext from '@/pages/api/home/home.context';\n\nimport Spinner from '../Spinner';\nimport { ChatInput } from './ChatInput';\nimport { ChatLoader } from './ChatLoader';\nimport { ErrorMessageDiv } from './ErrorMessageDiv';\nimport { ModelSelect } from './ModelSelect';\nimport { SystemPrompt } from './SystemPrompt';\nimport { TemperatureSlider } from './Temperature';\nimport { MemoizedChatMessage } from './MemoizedChatMessage';\n\ninterface Props {\n  stopConversationRef: MutableRefObject<boolean>;\n}\n\nexport const Chat = memo(({ stopConversationRef }: Props) => {\n  const { t } = useTranslation('chat');\n\n  const {\n    state: {\n      selectedConversation,\n      conversations,\n      models,\n      apiKey,\n      pluginKeys,\n      serverSideApiKeyIsSet,\n      messageIsStreaming,\n      modelError,\n      loading,\n      prompts,\n    },\n    handleUpdateConversation,\n    dispatch: homeDispatch,\n  } = useContext(HomeContext);\n\n  const [currentMessage, setCurrentMessage] = useState<Message>();\n  const [autoScrollEnabled, setAutoScrollEnabled] = useState<boolean>(true);\n  const [showSettings, setShowSettings] = useState<boolean>(false);\n  const [showScrollDownButton, setShowScrollDownButton] =\n    useState<boolean>(false);\n\n  const messagesEndRef = useRef<HTMLDivElement>(null);\n  const chatContainerRef = useRef<HTMLDivElement>(null);\n  const textareaRef = useRef<HTMLTextAreaElement>(null);\n\n  const handleSend = useCallback(\n    async (message: Message, deleteCount = 0, plugin: Plugin | null = null) => {\n      if (selectedConversation) {\n        let updatedConversation: Conversation;\n        if (deleteCount) {\n          const updatedMessages = [...selectedConversation.messages];\n          for (let i = 0; i < deleteCount; i++) {\n            updatedMessages.pop();\n          }\n          updatedConversation = {\n            ...selectedConversation,\n            messages: [...updatedMessages, message],\n          };\n        } else {\n          updatedConversation = {\n            ...selectedConversation,\n            messages: [...selectedConversation.messages, message],\n          };\n        }\n        homeDispatch({\n          field: 'selectedConversation',\n          value: updatedConversation,\n        });\n        homeDispatch({ field: 'loading', value: true });\n        homeDispatch({ field: 'messageIsStreaming', value: true });\n        const chatBody: ChatBody = {\n          model: updatedConversation.model,\n          messages: updatedConversation.messages,\n          key: apiKey,\n          prompt: updatedConversation.prompt,\n          temperature: updatedConversation.temperature,\n        };\n        const endpoint = getEndpoint(plugin);\n        let body;\n        if (!plugin) {\n          body = JSON.stringify(chatBody);\n        } else {\n          body = JSON.stringify({\n            ...chatBody,\n            googleAPIKey: pluginKeys\n              .find((key) => key.pluginId === 'google-search')\n              ?.requiredKeys.find((key) => key.key === 'GOOGLE_API_KEY')?.value,\n            googleCSEId: pluginKeys\n              .find((key) => key.pluginId === 'google-search')\n              ?.requiredKeys.find((key) => key.key === 'GOOGLE_CSE_ID')?.value,\n          });\n        }\n        const controller = new AbortController();\n        const response = await fetch(endpoint, {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n          },\n          signal: controller.signal,\n          body,\n        });\n        if (!response.ok) {\n          homeDispatch({ field: 'loading', value: false });\n          homeDispatch({ field: 'messageIsStreaming', value: false });\n          toast.error(response.statusText);\n          return;\n        }\n        const data = response.body;\n        if (!data) {\n          homeDispatch({ field: 'loading', value: false });\n          homeDispatch({ field: 'messageIsStreaming', value: false });\n          return;\n        }\n        if (!plugin) {\n          if (updatedConversation.messages.length === 1) {\n            const { content } = message;\n            const customName =\n              content.length > 30 ? content.substring(0, 30) + '...' : content;\n            updatedConversation = {\n              ...updatedConversation,\n              name: customName,\n            };\n          }\n          homeDispatch({ field: 'loading', value: false });\n          const reader = data.getReader();\n          const decoder = new TextDecoder();\n          let done = false;\n          let isFirst = true;\n          let text = '';\n          while (!done) {\n            if (stopConversationRef.current === true) {\n              controller.abort();\n              done = true;\n              break;\n            }\n            const { value, done: doneReading } = await reader.read();\n            done = doneReading;\n            const chunkValue = decoder.decode(value);\n            text += chunkValue;\n            if (isFirst) {\n              isFirst = false;\n              const updatedMessages: Message[] = [\n                ...updatedConversation.messages,\n                { role: 'assistant', content: chunkValue },\n              ];\n              updatedConversation = {\n                ...updatedConversation,\n                messages: updatedMessages,\n              };\n              homeDispatch({\n                field: 'selectedConversation',\n                value: updatedConversation,\n              });\n            } else {\n              const updatedMessages: Message[] =\n                updatedConversation.messages.map((message, index) => {\n                  if (index === updatedConversation.messages.length - 1) {\n                    return {\n                      ...message,\n                      content: text,\n                    };\n                  }\n                  return message;\n                });\n              updatedConversation = {\n                ...updatedConversation,\n                messages: updatedMessages,\n              };\n              homeDispatch({\n                field: 'selectedConversation',\n                value: updatedConversation,\n              });\n            }\n          }\n          saveConversation(updatedConversation);\n          const updatedConversations: Conversation[] = conversations.map(\n            (conversation) => {\n              if (conversation.id === selectedConversation.id) {\n                return updatedConversation;\n              }\n              return conversation;\n            },\n          );\n          if (updatedConversations.length === 0) {\n            updatedConversations.push(updatedConversation);\n          }\n          homeDispatch({ field: 'conversations', value: updatedConversations });\n          saveConversations(updatedConversations);\n          homeDispatch({ field: 'messageIsStreaming', value: false });\n        } else {\n          const { answer } = await response.json();\n          const updatedMessages: Message[] = [\n            ...updatedConversation.messages,\n            { role: 'assistant', content: answer },\n          ];\n          updatedConversation = {\n            ...updatedConversation,\n            messages: updatedMessages,\n          };\n          homeDispatch({\n            field: 'selectedConversation',\n            value: updateConversation,\n          });\n          saveConversation(updatedConversation);\n          const updatedConversations: Conversation[] = conversations.map(\n            (conversation) => {\n              if (conversation.id === selectedConversation.id) {\n                return updatedConversation;\n              }\n              return conversation;\n            },\n          );\n          if (updatedConversations.length === 0) {\n            updatedConversations.push(updatedConversation);\n          }\n          homeDispatch({ field: 'conversations', value: updatedConversations });\n          saveConversations(updatedConversations);\n          homeDispatch({ field: 'loading', value: false });\n          homeDispatch({ field: 'messageIsStreaming', value: false });\n        }\n      }\n    },\n    [\n      apiKey,\n      conversations,\n      pluginKeys,\n      selectedConversation,\n      stopConversationRef,\n    ],\n  );\n\n  const scrollToBottom = useCallback(() => {\n    if (autoScrollEnabled) {\n      messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });\n      textareaRef.current?.focus();\n    }\n  }, [autoScrollEnabled]);\n\n  const handleScroll = () => {\n    if (chatContainerRef.current) {\n      const { scrollTop, scrollHeight, clientHeight } =\n        chatContainerRef.current;\n      const bottomTolerance = 30;\n\n      if (scrollTop + clientHeight < scrollHeight - bottomTolerance) {\n        setAutoScrollEnabled(false);\n        setShowScrollDownButton(true);\n      } else {\n        setAutoScrollEnabled(true);\n        setShowScrollDownButton(false);\n      }\n    }\n  };\n\n  const handleScrollDown = () => {\n    chatContainerRef.current?.scrollTo({\n      top: chatContainerRef.current.scrollHeight,\n      behavior: 'smooth',\n    });\n  };\n\n  const handleSettings = () => {\n    setShowSettings(!showSettings);\n  };\n\n  const onClearAll = () => {\n    if (\n      confirm(t<string>('Are you sure you want to clear all messages?')) &&\n      selectedConversation\n    ) {\n      handleUpdateConversation(selectedConversation, {\n        key: 'messages',\n        value: [],\n      });\n    }\n  };\n\n  const scrollDown = () => {\n    if (autoScrollEnabled) {\n      messagesEndRef.current?.scrollIntoView(true);\n    }\n  };\n  const throttledScrollDown = throttle(scrollDown, 250);\n\n  // useEffect(() => {\n  //   console.log('currentMessage', currentMessage);\n  //   if (currentMessage) {\n  //     handleSend(currentMessage);\n  //     homeDispatch({ field: 'currentMessage', value: undefined });\n  //   }\n  // }, [currentMessage]);\n\n  useEffect(() => {\n    throttledScrollDown();\n    selectedConversation &&\n      setCurrentMessage(\n        selectedConversation.messages[selectedConversation.messages.length - 2],\n      );\n  }, [selectedConversation, throttledScrollDown]);\n\n  useEffect(() => {\n    const observer = new IntersectionObserver(\n      ([entry]) => {\n        setAutoScrollEnabled(entry.isIntersecting);\n        if (entry.isIntersecting) {\n          textareaRef.current?.focus();\n        }\n      },\n      {\n        root: null,\n        threshold: 0.5,\n      },\n    );\n    const messagesEndElement = messagesEndRef.current;\n    if (messagesEndElement) {\n      observer.observe(messagesEndElement);\n    }\n    return () => {\n      if (messagesEndElement) {\n        observer.unobserve(messagesEndElement);\n      }\n    };\n  }, [messagesEndRef]);\n\n  return (\n    <div className=\"relative flex-1 overflow-hidden bg-white dark:bg-[#343541]\">\n      {!(apiKey || serverSideApiKeyIsSet) ? (\n        <div className=\"mx-auto flex h-full w-[300px] flex-col justify-center space-y-6 sm:w-[600px]\">\n          <div className=\"text-center text-4xl font-bold text-black dark:text-white\">\n            Welcome to Chatbot UI\n          </div>\n          <div className=\"text-center text-lg text-black dark:text-white\">\n            <div className=\"mb-8\">{`Chatbot UI is an open source clone of OpenAI's ChatGPT UI.`}</div>\n            <div className=\"mb-2 font-bold\">\n              Important: Chatbot UI is 100% unaffiliated with OpenAI.\n            </div>\n          </div>\n          <div className=\"text-center text-gray-500 dark:text-gray-400\">\n            <div className=\"mb-2\">\n              Chatbot UI allows you to plug in your API key to use this UI with\n              their API.\n            </div>\n            <div className=\"mb-2\">\n              It is <span className=\"italic\">only</span> used to communicate\n              with their API.\n            </div>\n            <div className=\"mb-2\">\n              {t(\n                'Please set your OpenAI API key in the bottom left of the sidebar.',\n              )}\n            </div>\n            <div>\n              {t(\"If you don't have an OpenAI API key, you can get one here: \")}\n              <a\n                href=\"https://platform.openai.com/account/api-keys\"\n                target=\"_blank\"\n                rel=\"noreferrer\"\n                className=\"text-blue-500 hover:underline\"\n              >\n                openai.com\n              </a>\n            </div>\n          </div>\n        </div>\n      ) : modelError ? (\n        <ErrorMessageDiv error={modelError} />\n      ) : (\n        <>\n          <div\n            className=\"max-h-full overflow-x-hidden\"\n            ref={chatContainerRef}\n            onScroll={handleScroll}\n          >\n            {selectedConversation?.messages.length === 0 ? (\n              <>\n                <div className=\"mx-auto flex flex-col space-y-5 md:space-y-10 px-3 pt-5 md:pt-12 sm:max-w-[600px]\">\n                  <div className=\"text-center text-3xl font-semibold text-gray-800 dark:text-gray-100\">\n                    {models.length === 0 ? (\n                      <div>\n                        <Spinner size=\"16px\" className=\"mx-auto\" />\n                      </div>\n                    ) : (\n                      'Chatbot UI'\n                    )}\n                  </div>\n\n                  {models.length > 0 && (\n                    <div className=\"flex h-full flex-col space-y-4 rounded-lg border border-neutral-200 p-4 dark:border-neutral-600\">\n                      <ModelSelect />\n\n                      <SystemPrompt\n                        conversation={selectedConversation}\n                        prompts={prompts}\n                        onChangePrompt={(prompt) =>\n                          handleUpdateConversation(selectedConversation, {\n                            key: 'prompt',\n                            value: prompt,\n                          })\n                        }\n                      />\n\n                      <TemperatureSlider\n                        label={t('Temperature')}\n                        onChangeTemperature={(temperature) =>\n                          handleUpdateConversation(selectedConversation, {\n                            key: 'temperature',\n                            value: temperature,\n                          })\n                        }\n                      />\n                    </div>\n                  )}\n                </div>\n              </>\n            ) : (\n              <>\n                <div className=\"sticky top-0 z-10 flex justify-center border border-b-neutral-300 bg-neutral-100 py-2 text-sm text-neutral-500 dark:border-none dark:bg-[#444654] dark:text-neutral-200\">\n                  {t('Model')}: {selectedConversation?.model.name} | {t('Temp')}\n                  : {selectedConversation?.temperature} |\n                  <button\n                    className=\"ml-2 cursor-pointer hover:opacity-50\"\n                    onClick={handleSettings}\n                  >\n                    <IconSettings size={18} />\n                  </button>\n                  <button\n                    className=\"ml-2 cursor-pointer hover:opacity-50\"\n                    onClick={onClearAll}\n                  >\n                    <IconClearAll size={18} />\n                  </button>\n                </div>\n                {showSettings && (\n                  <div className=\"flex flex-col space-y-10 md:mx-auto md:max-w-xl md:gap-6 md:py-3 md:pt-6 lg:max-w-2xl lg:px-0 xl:max-w-3xl\">\n                    <div className=\"flex h-full flex-col space-y-4 border-b border-neutral-200 p-4 dark:border-neutral-600 md:rounded-lg md:border\">\n                      <ModelSelect />\n                    </div>\n                  </div>\n                )}\n\n                {selectedConversation?.messages.map((message, index) => (\n                  <MemoizedChatMessage\n                    key={index}\n                    message={message}\n                    messageIndex={index}\n                    onEdit={(editedMessage) => {\n                      setCurrentMessage(editedMessage);\n                      // discard edited message and the ones that come after then resend\n                      handleSend(\n                        editedMessage,\n                        selectedConversation?.messages.length - index,\n                      );\n                    }}\n                  />\n                ))}\n\n                {loading && <ChatLoader />}\n\n                <div\n                  className=\"h-[162px] bg-white dark:bg-[#343541]\"\n                  ref={messagesEndRef}\n                />\n              </>\n            )}\n          </div>\n\n          <ChatInput\n            stopConversationRef={stopConversationRef}\n            textareaRef={textareaRef}\n            onSend={(message, plugin) => {\n              setCurrentMessage(message);\n              handleSend(message, 0, plugin);\n            }}\n            onScrollDownClick={handleScrollDown}\n            onRegenerate={() => {\n              if (currentMessage) {\n                handleSend(currentMessage, 2, null);\n              }\n            }}\n            showScrollDownButton={showScrollDownButton}\n          />\n        </>\n      )}\n    </div>\n  );\n});\nChat.displayName = 'Chat';\n","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ChatInput.tsx",["306"],[],"import {\n  IconArrowDown,\n  IconBolt,\n  IconBrandGoogle,\n  IconPlayerStop,\n  IconRepeat,\n  IconSend,\n} from '@tabler/icons-react';\nimport {\n  KeyboardEvent,\n  MutableRefObject,\n  useCallback,\n  useContext,\n  useEffect,\n  useRef,\n  useState,\n} from 'react';\n\nimport { useTranslation } from 'next-i18next';\n\nimport { Message } from '@/types/chat';\nimport { Plugin } from '@/types/plugin';\nimport { Prompt } from '@/types/prompt';\n\nimport HomeContext from '@/pages/api/home/home.context';\n\nimport { PluginSelect } from './PluginSelect';\nimport { PromptList } from './PromptList';\nimport { VariableModal } from './VariableModal';\n\ninterface Props {\n  onSend: (message: Message, plugin: Plugin | null) => void;\n  onRegenerate: () => void;\n  onScrollDownClick: () => void;\n  stopConversationRef: MutableRefObject<boolean>;\n  textareaRef: MutableRefObject<HTMLTextAreaElement | null>;\n  showScrollDownButton: boolean;\n}\n\nexport const ChatInput = ({\n  onSend,\n  onRegenerate,\n  onScrollDownClick,\n  stopConversationRef,\n  textareaRef,\n  showScrollDownButton,\n}: Props) => {\n  const { t } = useTranslation('chat');\n\n  const {\n    state: { selectedConversation, messageIsStreaming, prompts },\n\n    dispatch: homeDispatch,\n  } = useContext(HomeContext);\n\n  const [content, setContent] = useState<string>();\n  const [isTyping, setIsTyping] = useState<boolean>(false);\n  const [showPromptList, setShowPromptList] = useState(false);\n  const [activePromptIndex, setActivePromptIndex] = useState(0);\n  const [promptInputValue, setPromptInputValue] = useState('');\n  const [variables, setVariables] = useState<string[]>([]);\n  const [isModalVisible, setIsModalVisible] = useState(false);\n  const [showPluginSelect, setShowPluginSelect] = useState(false);\n  const [plugin, setPlugin] = useState<Plugin | null>(null);\n\n  const promptListRef = useRef<HTMLUListElement | null>(null);\n\n  const filteredPrompts = prompts.filter((prompt) =>\n    prompt.name.toLowerCase().includes(promptInputValue.toLowerCase()),\n  );\n\n  const handleChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {\n    const value = e.target.value;\n    const maxLength = selectedConversation?.model.maxLength;\n\n    if (maxLength && value.length > maxLength) {\n      alert(\n        t(\n          `Message limit is {{maxLength}} characters. You have entered {{valueLength}} characters.`,\n          { maxLength, valueLength: value.length },\n        ),\n      );\n      return;\n    }\n\n    setContent(value);\n    updatePromptListVisibility(value);\n  };\n\n  const handleSend = () => {\n    if (messageIsStreaming) {\n      return;\n    }\n\n    if (!content) {\n      alert(t('Please enter a message'));\n      return;\n    }\n\n    onSend({ role: 'user', content }, plugin);\n    setContent('');\n    setPlugin(null);\n\n    if (window.innerWidth < 640 && textareaRef && textareaRef.current) {\n      textareaRef.current.blur();\n    }\n  };\n\n  const handleStopConversation = () => {\n    stopConversationRef.current = true;\n    setTimeout(() => {\n      stopConversationRef.current = false;\n    }, 1000);\n  };\n\n  const isMobile = () => {\n    const userAgent =\n      typeof window.navigator === 'undefined' ? '' : navigator.userAgent;\n    const mobileRegex =\n      /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini|Mobile|mobile|CriOS/i;\n    return mobileRegex.test(userAgent);\n  };\n\n  const handleInitModal = () => {\n    const selectedPrompt = filteredPrompts[activePromptIndex];\n    if (selectedPrompt) {\n      setContent((prevContent) => {\n        const newContent = prevContent?.replace(\n          /\\/\\w*$/,\n          selectedPrompt.content,\n        );\n        return newContent;\n      });\n      handlePromptSelect(selectedPrompt);\n    }\n    setShowPromptList(false);\n  };\n\n  const handleKeyDown = (e: KeyboardEvent<HTMLTextAreaElement>) => {\n    if (showPromptList) {\n      if (e.key === 'ArrowDown') {\n        e.preventDefault();\n        setActivePromptIndex((prevIndex) =>\n          prevIndex < prompts.length - 1 ? prevIndex + 1 : prevIndex,\n        );\n      } else if (e.key === 'ArrowUp') {\n        e.preventDefault();\n        setActivePromptIndex((prevIndex) =>\n          prevIndex > 0 ? prevIndex - 1 : prevIndex,\n        );\n      } else if (e.key === 'Tab') {\n        e.preventDefault();\n        setActivePromptIndex((prevIndex) =>\n          prevIndex < prompts.length - 1 ? prevIndex + 1 : 0,\n        );\n      } else if (e.key === 'Enter') {\n        e.preventDefault();\n        handleInitModal();\n      } else if (e.key === 'Escape') {\n        e.preventDefault();\n        setShowPromptList(false);\n      } else {\n        setActivePromptIndex(0);\n      }\n    } else if (e.key === 'Enter' && !isTyping && !isMobile() && !e.shiftKey) {\n      e.preventDefault();\n      handleSend();\n    } else if (e.key === '/' && e.metaKey) {\n      e.preventDefault();\n      setShowPluginSelect(!showPluginSelect);\n    }\n  };\n\n  const parseVariables = (content: string) => {\n    const regex = /{{(.*?)}}/g;\n    const foundVariables = [];\n    let match;\n\n    while ((match = regex.exec(content)) !== null) {\n      foundVariables.push(match[1]);\n    }\n\n    return foundVariables;\n  };\n\n  const updatePromptListVisibility = useCallback((text: string) => {\n    const match = text.match(/\\/\\w*$/);\n\n    if (match) {\n      setShowPromptList(true);\n      setPromptInputValue(match[0].slice(1));\n    } else {\n      setShowPromptList(false);\n      setPromptInputValue('');\n    }\n  }, []);\n\n  const handlePromptSelect = (prompt: Prompt) => {\n    const parsedVariables = parseVariables(prompt.content);\n    setVariables(parsedVariables);\n\n    if (parsedVariables.length > 0) {\n      setIsModalVisible(true);\n    } else {\n      setContent((prevContent) => {\n        const updatedContent = prevContent?.replace(/\\/\\w*$/, prompt.content);\n        return updatedContent;\n      });\n      updatePromptListVisibility(prompt.content);\n    }\n  };\n\n  const handleSubmit = (updatedVariables: string[]) => {\n    const newContent = content?.replace(/{{(.*?)}}/g, (match, variable) => {\n      const index = variables.indexOf(variable);\n      return updatedVariables[index];\n    });\n\n    setContent(newContent);\n\n    if (textareaRef && textareaRef.current) {\n      textareaRef.current.focus();\n    }\n  };\n\n  useEffect(() => {\n    if (promptListRef.current) {\n      promptListRef.current.scrollTop = activePromptIndex * 30;\n    }\n  }, [activePromptIndex]);\n\n  useEffect(() => {\n    if (textareaRef && textareaRef.current) {\n      textareaRef.current.style.height = 'inherit';\n      textareaRef.current.style.height = `${textareaRef.current?.scrollHeight}px`;\n      textareaRef.current.style.overflow = `${\n        textareaRef?.current?.scrollHeight > 400 ? 'auto' : 'hidden'\n      }`;\n    }\n  }, [content]);\n\n  useEffect(() => {\n    const handleOutsideClick = (e: MouseEvent) => {\n      if (\n        promptListRef.current &&\n        !promptListRef.current.contains(e.target as Node)\n      ) {\n        setShowPromptList(false);\n      }\n    };\n\n    window.addEventListener('click', handleOutsideClick);\n\n    return () => {\n      window.removeEventListener('click', handleOutsideClick);\n    };\n  }, []);\n\n  return (\n    <div className=\"absolute bottom-0 left-0 w-full border-transparent bg-gradient-to-b from-transparent via-white to-white pt-6 dark:border-white/20 dark:via-[#343541] dark:to-[#343541] md:pt-2\">\n      <div className=\"stretch mx-2 mt-4 flex flex-row gap-3 last:mb-2 md:mx-4 md:mt-[52px] md:last:mb-6 lg:mx-auto lg:max-w-3xl\">\n        {messageIsStreaming && (\n          <button\n            className=\"absolute top-0 left-0 right-0 mx-auto mb-3 flex w-fit items-center gap-3 rounded border border-neutral-200 bg-white py-2 px-4 text-black hover:opacity-50 dark:border-neutral-600 dark:bg-[#343541] dark:text-white md:mb-0 md:mt-2\"\n            onClick={handleStopConversation}\n          >\n            <IconPlayerStop size={16} /> {t('Stop Generating')}\n          </button>\n        )}\n\n        {!messageIsStreaming &&\n          selectedConversation &&\n          selectedConversation.messages.length > 0 && (\n            <button\n              className=\"absolute top-0 left-0 right-0 mx-auto mb-3 flex w-fit items-center gap-3 rounded border border-neutral-200 bg-white py-2 px-4 text-black hover:opacity-50 dark:border-neutral-600 dark:bg-[#343541] dark:text-white md:mb-0 md:mt-2\"\n              onClick={onRegenerate}\n            >\n              <IconRepeat size={16} /> {t('Regenerate response')}\n            </button>\n          )}\n\n        <div className=\"relative mx-2 flex w-full flex-grow flex-col rounded-md border border-black/10 bg-white shadow-[0_0_10px_rgba(0,0,0,0.10)] dark:border-gray-900/50 dark:bg-[#40414F] dark:text-white dark:shadow-[0_0_15px_rgba(0,0,0,0.10)] sm:mx-4\">\n          <button\n            className=\"absolute left-2 top-2 rounded-sm p-1 text-neutral-800 opacity-60 hover:bg-neutral-200 hover:text-neutral-900 dark:bg-opacity-50 dark:text-neutral-100 dark:hover:text-neutral-200\"\n            onClick={() => setShowPluginSelect(!showPluginSelect)}\n            onKeyDown={(e) => {}}\n          >\n            {plugin ? <IconBrandGoogle size={20} /> : <IconBolt size={20} />}\n          </button>\n\n          {showPluginSelect && (\n            <div className=\"absolute left-0 bottom-14 rounded bg-white dark:bg-[#343541]\">\n              <PluginSelect\n                plugin={plugin}\n                onKeyDown={(e: any) => {\n                  if (e.key === 'Escape') {\n                    e.preventDefault();\n                    setShowPluginSelect(false);\n                    textareaRef.current?.focus();\n                  }\n                }}\n                onPluginChange={(plugin: Plugin) => {\n                  setPlugin(plugin);\n                  setShowPluginSelect(false);\n\n                  if (textareaRef && textareaRef.current) {\n                    textareaRef.current.focus();\n                  }\n                }}\n              />\n            </div>\n          )}\n\n          <textarea\n            ref={textareaRef}\n            className=\"m-0 w-full resize-none border-0 bg-transparent p-0 py-2 pr-8 pl-10 text-black dark:bg-transparent dark:text-white md:py-3 md:pl-10\"\n            style={{\n              resize: 'none',\n              bottom: `${textareaRef?.current?.scrollHeight}px`,\n              maxHeight: '400px',\n              overflow: `${\n                textareaRef.current && textareaRef.current.scrollHeight > 400\n                  ? 'auto'\n                  : 'hidden'\n              }`,\n            }}\n            placeholder={\n              t('Type a message or type \"/\" to select a prompt...') || ''\n            }\n            value={content}\n            rows={1}\n            onCompositionStart={() => setIsTyping(true)}\n            onCompositionEnd={() => setIsTyping(false)}\n            onChange={handleChange}\n            onKeyDown={handleKeyDown}\n          />\n\n          <button\n            className=\"absolute right-2 top-2 rounded-sm p-1 text-neutral-800 opacity-60 hover:bg-neutral-200 hover:text-neutral-900 dark:bg-opacity-50 dark:text-neutral-100 dark:hover:text-neutral-200\"\n            onClick={handleSend}\n          >\n            {messageIsStreaming ? (\n              <div className=\"h-4 w-4 animate-spin rounded-full border-t-2 border-neutral-800 opacity-60 dark:border-neutral-100\"></div>\n            ) : (\n              <IconSend size={18} />\n            )}\n          </button>\n\n          {showScrollDownButton && (\n            <div className=\"absolute bottom-12 right-0 lg:bottom-0 lg:-right-10\">\n              <button\n                className=\"flex h-7 w-7 items-center justify-center rounded-full bg-neutral-300 text-gray-800 shadow-md hover:shadow-lg focus:outline-none focus:ring-2 focus:ring-blue-500 dark:bg-gray-700 dark:text-neutral-200\"\n                onClick={onScrollDownClick}\n              >\n                <IconArrowDown size={18} />\n              </button>\n            </div>\n          )}\n\n          {showPromptList && filteredPrompts.length > 0 && (\n            <div className=\"absolute bottom-12 w-full\">\n              <PromptList\n                activePromptIndex={activePromptIndex}\n                prompts={filteredPrompts}\n                onSelect={handleInitModal}\n                onMouseOver={setActivePromptIndex}\n                promptListRef={promptListRef}\n              />\n            </div>\n          )}\n\n          {isModalVisible && (\n            <VariableModal\n              prompt={filteredPrompts[activePromptIndex]}\n              variables={variables}\n              onSubmit={handleSubmit}\n              onClose={() => setIsModalVisible(false)}\n            />\n          )}\n        </div>\n      </div>\n      <div className=\"px-3 pt-2 pb-3 text-center text-[12px] text-black/50 dark:text-white/50 md:px-4 md:pt-3 md:pb-6\">\n        <a\n          href=\"https://github.com/mckaywrigley/chatbot-ui\"\n          target=\"_blank\"\n          rel=\"noreferrer\"\n          className=\"underline\"\n        >\n          ChatBot UI\n        </a>\n        .{' '}\n        {t(\n          \"Chatbot UI is an advanced chatbot kit for OpenAI's chat models aiming to mimic ChatGPT's interface and functionality.\",\n        )}\n      </div>\n    </div>\n  );\n};\n","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ChatLoader.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ChatMessage.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ErrorMessageDiv.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\MemoizedChatMessage.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\ModelSelect.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\PluginSelect.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\PromptList.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\Regenerate.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\SystemPrompt.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\Temperature.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chat\\VariableModal.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\Chatbar.context.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\Chatbar.state.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\Chatbar.tsx",["307"],[],"import { useCallback, useContext, useEffect } from 'react';\r\n\r\nimport { useTranslation } from 'next-i18next';\r\n\r\nimport { useCreateReducer } from '@/hooks/useCreateReducer';\r\n\r\nimport { DEFAULT_SYSTEM_PROMPT, DEFAULT_TEMPERATURE } from '@/utils/app/const';\r\nimport { saveConversation, saveConversations } from '@/utils/app/conversation';\r\nimport { saveFolders } from '@/utils/app/folders';\r\nimport { exportData, exportData_asPDF, importData } from '@/utils/app/importExport';\r\n\r\nimport { Conversation } from '@/types/chat';\r\nimport { LatestExportFormat, SupportedExportFormats } from '@/types/export';\r\nimport { OpenAIModels } from '@/types/openai';\r\nimport { PluginKey } from '@/types/plugin';\r\n\r\nimport HomeContext from '@/pages/api/home/home.context';\r\n\r\nimport { ChatFolders } from './components/ChatFolders';\r\nimport { ChatbarSettings } from './components/ChatbarSettings';\r\nimport { Conversations } from './components/Conversations';\r\n\r\nimport Sidebar from '../Sidebar';\r\nimport ChatbarContext from './Chatbar.context';\r\nimport { ChatbarInitialState, initialState } from './Chatbar.state';\r\n\r\nimport { v4 as uuidv4 } from 'uuid';\r\n\r\nexport const Chatbar = () => {\r\n  const { t } = useTranslation('sidebar');\r\n\r\n  const chatBarContextValue = useCreateReducer<ChatbarInitialState>({\r\n    initialState,\r\n  });\r\n\r\n  const {\r\n    state: { conversations, showChatbar, defaultModelId, folders, pluginKeys },\r\n    dispatch: homeDispatch,\r\n    handleCreateFolder,\r\n    handleNewConversation,\r\n    handleUpdateConversation,\r\n  } = useContext(HomeContext);\r\n\r\n  const {\r\n    state: { searchTerm, filteredConversations },\r\n    dispatch: chatDispatch,\r\n  } = chatBarContextValue;\r\n\r\n  const handleApiKeyChange = useCallback(\r\n    (apiKey: string) => {\r\n      homeDispatch({ field: 'apiKey', value: apiKey });\r\n\r\n      localStorage.setItem('apiKey', apiKey);\r\n    },\r\n    [homeDispatch],\r\n  );\r\n\r\n  const handlePluginKeyChange = (pluginKey: PluginKey) => {\r\n    if (pluginKeys.some((key) => key.pluginId === pluginKey.pluginId)) {\r\n      const updatedPluginKeys = pluginKeys.map((key) => {\r\n        if (key.pluginId === pluginKey.pluginId) {\r\n          return pluginKey;\r\n        }\r\n\r\n        return key;\r\n      });\r\n\r\n      homeDispatch({ field: 'pluginKeys', value: updatedPluginKeys });\r\n\r\n      localStorage.setItem('pluginKeys', JSON.stringify(updatedPluginKeys));\r\n    } else {\r\n      homeDispatch({ field: 'pluginKeys', value: [...pluginKeys, pluginKey] });\r\n\r\n      localStorage.setItem(\r\n        'pluginKeys',\r\n        JSON.stringify([...pluginKeys, pluginKey]),\r\n      );\r\n    }\r\n  };\r\n\r\n  const handleClearPluginKey = (pluginKey: PluginKey) => {\r\n    const updatedPluginKeys = pluginKeys.filter(\r\n      (key) => key.pluginId !== pluginKey.pluginId,\r\n    );\r\n\r\n    if (updatedPluginKeys.length === 0) {\r\n      homeDispatch({ field: 'pluginKeys', value: [] });\r\n      localStorage.removeItem('pluginKeys');\r\n      return;\r\n    }\r\n\r\n    homeDispatch({ field: 'pluginKeys', value: updatedPluginKeys });\r\n\r\n    localStorage.setItem('pluginKeys', JSON.stringify(updatedPluginKeys));\r\n  };\r\n\r\n  const handleExportData = () => {\r\n    exportData();\r\n  };\r\n\r\n  const handleExportData_asPDF = () => {\r\n    exportData_asPDF();\r\n  };\r\n\r\n  const handleImportConversations = (data: SupportedExportFormats) => {\r\n    const { history, folders, prompts }: LatestExportFormat = importData(data);\r\n    homeDispatch({ field: 'conversations', value: history });\r\n    homeDispatch({\r\n      field: 'selectedConversation',\r\n      value: history[history.length - 1],\r\n    });\r\n    homeDispatch({ field: 'folders', value: folders });\r\n    homeDispatch({ field: 'prompts', value: prompts });\r\n\r\n    window.location.reload();\r\n  };\r\n\r\n  const handleClearConversations = () => {\r\n    defaultModelId &&\r\n      homeDispatch({\r\n        field: 'selectedConversation',\r\n        value: {\r\n          id: uuidv4(),\r\n          name: t('New Conversation'),\r\n          messages: [],\r\n          model: OpenAIModels[defaultModelId],\r\n          prompt: DEFAULT_SYSTEM_PROMPT,\r\n          temperature: DEFAULT_TEMPERATURE,\r\n          folderId: null,\r\n        },\r\n      });\r\n\r\n    homeDispatch({ field: 'conversations', value: [] });\r\n\r\n    localStorage.removeItem('conversationHistory');\r\n    localStorage.removeItem('selectedConversation');\r\n\r\n    const updatedFolders = folders.filter((f) => f.type !== 'chat');\r\n\r\n    homeDispatch({ field: 'folders', value: updatedFolders });\r\n    saveFolders(updatedFolders);\r\n  };\r\n\r\n  const handleDeleteConversation = (conversation: Conversation) => {\r\n    const updatedConversations = conversations.filter(\r\n      (c) => c.id !== conversation.id,\r\n    );\r\n\r\n    homeDispatch({ field: 'conversations', value: updatedConversations });\r\n    chatDispatch({ field: 'searchTerm', value: '' });\r\n    saveConversations(updatedConversations);\r\n\r\n    if (updatedConversations.length > 0) {\r\n      homeDispatch({\r\n        field: 'selectedConversation',\r\n        value: updatedConversations[updatedConversations.length - 1],\r\n      });\r\n\r\n      saveConversation(updatedConversations[updatedConversations.length - 1]);\r\n    } else {\r\n      defaultModelId &&\r\n        homeDispatch({\r\n          field: 'selectedConversation',\r\n          value: {\r\n            id: uuidv4(),\r\n            name: t('New Conversation'),\r\n            messages: [],\r\n            model: OpenAIModels[defaultModelId],\r\n            prompt: DEFAULT_SYSTEM_PROMPT,\r\n            temperature: DEFAULT_TEMPERATURE,\r\n            folderId: null,\r\n          },\r\n        });\r\n\r\n      localStorage.removeItem('selectedConversation');\r\n    }\r\n  };\r\n\r\n  const handleToggleChatbar = () => {\r\n    homeDispatch({ field: 'showChatbar', value: !showChatbar });\r\n    localStorage.setItem('showChatbar', JSON.stringify(!showChatbar));\r\n  };\r\n\r\n  const handleDrop = (e: any) => {\r\n    if (e.dataTransfer) {\r\n      const conversation = JSON.parse(e.dataTransfer.getData('conversation'));\r\n      handleUpdateConversation(conversation, { key: 'folderId', value: 0 });\r\n      chatDispatch({ field: 'searchTerm', value: '' });\r\n      e.target.style.background = 'none';\r\n    }\r\n  };\r\n\r\n  useEffect(() => {\r\n    if (searchTerm) {\r\n      chatDispatch({\r\n        field: 'filteredConversations',\r\n        value: conversations.filter((conversation) => {\r\n          const searchable =\r\n            conversation.name.toLocaleLowerCase() +\r\n            ' ' +\r\n            conversation.messages.map((message) => message.content).join(' ');\r\n          return searchable.toLowerCase().includes(searchTerm.toLowerCase());\r\n        }),\r\n      });\r\n    } else {\r\n      chatDispatch({\r\n        field: 'filteredConversations',\r\n        value: conversations,\r\n      });\r\n    }\r\n  }, [searchTerm, conversations]);\r\n\r\n  return (\r\n    <ChatbarContext.Provider\r\n      value={{\r\n        ...chatBarContextValue,\r\n        handleDeleteConversation,\r\n        handleClearConversations,\r\n        handleImportConversations,\r\n        handleExportData,\r\n        handleExportData_asPDF,\r\n        handlePluginKeyChange,\r\n        handleClearPluginKey,\r\n        handleApiKeyChange,\r\n      }}\r\n    >\r\n      <Sidebar<Conversation>\r\n        side={'left'}\r\n        isOpen={showChatbar}\r\n        addItemButtonTitle={t('New chat')}\r\n        itemComponent={<Conversations conversations={filteredConversations} />}\r\n        folderComponent={<ChatFolders searchTerm={searchTerm} />}\r\n        items={filteredConversations}\r\n        searchTerm={searchTerm}\r\n        handleSearchTerm={(searchTerm: string) =>\r\n          chatDispatch({ field: 'searchTerm', value: searchTerm })\r\n        }\r\n        toggleOpen={handleToggleChatbar}\r\n        handleCreateItem={handleNewConversation}\r\n        handleCreateFolder={() => handleCreateFolder(t('New folder'), 'chat')}\r\n        handleDrop={handleDrop}\r\n        footerComponent={<ChatbarSettings />}\r\n      />\r\n    </ChatbarContext.Provider>\r\n  );\r\n};\r\n","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\ChatbarSettings.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\ChatFolders.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\ClearConversations.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\Conversation.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\Conversations.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Chatbar\\components\\PluginKeys.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Folder\\Folder.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Folder\\index.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Markdown\\CodeBlock.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Markdown\\MemoizedReactMarkdown.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Mobile\\Navbar.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\Prompt.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\PromptbarSettings.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\PromptFolders.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\PromptModal.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\components\\Prompts.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\index.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\PromptBar.context.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\Promptbar.state.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Promptbar\\Promptbar.tsx",["308"],[],"import { useContext, useEffect, useState } from 'react';\nimport { useTranslation } from 'react-i18next';\n\nimport { useCreateReducer } from '@/hooks/useCreateReducer';\n\nimport { savePrompts } from '@/utils/app/prompts';\n\nimport { OpenAIModels } from '@/types/openai';\nimport { Prompt } from '@/types/prompt';\n\nimport HomeContext from '@/pages/api/home/home.context';\n\nimport { PromptFolders } from './components/PromptFolders';\nimport { PromptbarSettings } from './components/PromptbarSettings';\nimport { Prompts } from './components/Prompts';\n\nimport Sidebar from '../Sidebar';\nimport PromptbarContext from './PromptBar.context';\nimport { PromptbarInitialState, initialState } from './Promptbar.state';\n\nimport { v4 as uuidv4 } from 'uuid';\n\nconst Promptbar = () => {\n  const { t } = useTranslation('promptbar');\n\n  const promptBarContextValue = useCreateReducer<PromptbarInitialState>({\n    initialState,\n  });\n\n  const {\n    state: { prompts, defaultModelId, showPromptbar },\n    dispatch: homeDispatch,\n    handleCreateFolder,\n  } = useContext(HomeContext);\n\n  const {\n    state: { searchTerm, filteredPrompts },\n    dispatch: promptDispatch,\n  } = promptBarContextValue;\n\n  const handleTogglePromptbar = () => {\n    homeDispatch({ field: 'showPromptbar', value: !showPromptbar });\n    localStorage.setItem('showPromptbar', JSON.stringify(!showPromptbar));\n  };\n\n  const handleCreatePrompt = () => {\n    if (defaultModelId) {\n      const newPrompt: Prompt = {\n        id: uuidv4(),\n        name: `Prompt ${prompts.length + 1}`,\n        description: '',\n        content: '',\n        model: OpenAIModels[defaultModelId],\n        folderId: null,\n      };\n\n      const updatedPrompts = [...prompts, newPrompt];\n\n      homeDispatch({ field: 'prompts', value: updatedPrompts });\n\n      savePrompts(updatedPrompts);\n    }\n  };\n\n  const handleDeletePrompt = (prompt: Prompt) => {\n    const updatedPrompts = prompts.filter((p) => p.id !== prompt.id);\n\n    homeDispatch({ field: 'prompts', value: updatedPrompts });\n    savePrompts(updatedPrompts);\n  };\n\n  const handleUpdatePrompt = (prompt: Prompt) => {\n    const updatedPrompts = prompts.map((p) => {\n      if (p.id === prompt.id) {\n        return prompt;\n      }\n\n      return p;\n    });\n    homeDispatch({ field: 'prompts', value: updatedPrompts });\n\n    savePrompts(updatedPrompts);\n  };\n\n  const handleDrop = (e: any) => {\n    if (e.dataTransfer) {\n      const prompt = JSON.parse(e.dataTransfer.getData('prompt'));\n\n      const updatedPrompt = {\n        ...prompt,\n        folderId: e.target.dataset.folderId,\n      };\n\n      handleUpdatePrompt(updatedPrompt);\n\n      e.target.style.background = 'none';\n    }\n  };\n\n  useEffect(() => {\n    if (searchTerm) {\n      promptDispatch({\n        field: 'filteredPrompts',\n        value: prompts.filter((prompt) => {\n          const searchable =\n            prompt.name.toLowerCase() +\n            ' ' +\n            prompt.description.toLowerCase() +\n            ' ' +\n            prompt.content.toLowerCase();\n          return searchable.includes(searchTerm.toLowerCase());\n        }),\n      });\n    } else {\n      promptDispatch({ field: 'filteredPrompts', value: prompts });\n    }\n  }, [searchTerm, prompts]);\n\n  return (\n    <PromptbarContext.Provider\n      value={{\n        ...promptBarContextValue,\n        handleCreatePrompt,\n        handleDeletePrompt,\n        handleUpdatePrompt,\n      }}\n    >\n      <Sidebar<Prompt>\n        side={'right'}\n        isOpen={showPromptbar}\n        addItemButtonTitle={t('New prompt')}\n        itemComponent={\n          <Prompts\n            prompts={filteredPrompts.filter((prompt) => !prompt.folderId)}\n          />\n        }\n        folderComponent={<PromptFolders />}\n        items={filteredPrompts}\n        searchTerm={searchTerm}\n        handleSearchTerm={(searchTerm: string) =>\n          promptDispatch({ field: 'searchTerm', value: searchTerm })\n        }\n        toggleOpen={handleTogglePromptbar}\n        handleCreateItem={handleCreatePrompt}\n        handleCreateFolder={() => handleCreateFolder(t('New folder'), 'prompt')}\n        handleDrop={handleDrop}\n      />\n    </PromptbarContext.Provider>\n  );\n};\n\nexport default Promptbar;\n","C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Search\\index.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Search\\Search.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Settings\\Import.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Settings\\Key.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Settings\\SettingDialog.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\components\\OpenCloseButton.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\index.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\Sidebar.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Sidebar\\SidebarButton.tsx",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Spinner\\index.ts",[],[],"C:\\Users\\Thomas\\Documents\\GitHub\\PI-2023-BNP-OpenAI-Prospectus\\frontend\\components\\Spinner\\Spinner.tsx",[],[],{"ruleId":"309","severity":1,"message":"310","line":234,"column":6,"nodeType":"311","endLine":234,"endColumn":28,"suggestions":"312"},{"ruleId":"309","severity":1,"message":"310","line":249,"column":6,"nodeType":"311","endLine":249,"endColumn":70,"suggestions":"313"},{"ruleId":"309","severity":1,"message":"314","line":343,"column":6,"nodeType":"311","endLine":348,"endColumn":4,"suggestions":"315"},{"ruleId":"309","severity":1,"message":"316","line":248,"column":5,"nodeType":"311","endLine":254,"endColumn":6,"suggestions":"317"},{"ruleId":"309","severity":1,"message":"318","line":240,"column":6,"nodeType":"311","endLine":240,"endColumn":15,"suggestions":"319"},{"ruleId":"309","severity":1,"message":"320","line":211,"column":6,"nodeType":"311","endLine":211,"endColumn":33,"suggestions":"321"},{"ruleId":"309","severity":1,"message":"322","line":117,"column":6,"nodeType":"311","endLine":117,"endColumn":27,"suggestions":"323"},"react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'dispatch'. Either include it or remove the dependency array.","ArrayExpression",["324"],["325"],"React Hook useEffect has missing dependencies: 'conversations' and 't'. Either include them or remove the dependency array.",["326"],"React Hook useCallback has a missing dependency: 'homeDispatch'. Either include it or remove the dependency array.",["327"],"React Hook useEffect has a missing dependency: 'textareaRef'. Either include it or remove the dependency array.",["328"],"React Hook useEffect has a missing dependency: 'chatDispatch'. Either include it or remove the dependency array.",["329"],"React Hook useEffect has a missing dependency: 'promptDispatch'. Either include it or remove the dependency array.",["330"],{"desc":"331","fix":"332"},{"desc":"333","fix":"334"},{"desc":"335","fix":"336"},{"desc":"337","fix":"338"},{"desc":"339","fix":"340"},{"desc":"341","fix":"342"},{"desc":"343","fix":"344"},"Update the dependencies array to be: [dispatch, selectedConversation]",{"range":"345","text":"346"},"Update the dependencies array to be: [defaultModelId, dispatch, serverSideApiKeyIsSet, serverSidePluginKeysSet]",{"range":"347","text":"348"},"Update the dependencies array to be: [conversations, defaultModelId, dispatch, serverSideApiKeyIsSet, serverSidePluginKeysSet, t]",{"range":"349","text":"350"},"Update the dependencies array to be: [apiKey, conversations, homeDispatch, pluginKeys, selectedConversation, stopConversationRef]",{"range":"351","text":"352"},"Update the dependencies array to be: [content, textareaRef]",{"range":"353","text":"354"},"Update the dependencies array to be: [searchTerm, conversations, chatDispatch]",{"range":"355","text":"356"},"Update the dependencies array to be: [searchTerm, prompts, promptDispatch]",{"range":"357","text":"358"},[6582,6604],"[dispatch, selectedConversation]",[7012,7076],"[defaultModelId, dispatch, serverSideApiKeyIsSet, serverSidePluginKeysSet]",[10042,10142],"[conversations, defaultModelId, dispatch, serverSideApiKeyIsSet, serverSidePluginKeysSet, t]",[8584,8699],"[apiKey, conversations, homeDispatch, pluginKeys, selectedConversation, stopConversationRef]",[6701,6710],"[content, textareaRef]",[6697,6724],"[searchTerm, conversations, chatDispatch]",[3182,3203],"[searchTerm, prompts, promptDispatch]"]